{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Exemple d'utilisation d'un transfcormer dans le cadre de la génération de code.\n",
    "\n",
    "On utilise au chois les modeles\n",
    "\n",
    "* codegen-350M-mono\n",
    "* codegen-2B-mono\n",
    "*"
   ],
   "id": "221643bb67bb1c5f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-02T10:34:19.668299Z",
     "start_time": "2025-08-02T10:34:19.665954Z"
    }
   },
   "cell_type": "code",
   "source": "model_name = \"export_model/codegen-350M-mono_finetuned\"",
   "id": "e0d7ac62e8466100",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Observations\n",
    "\n",
    "* En promptant sur un debut de code le model est capable de prédire du code correcte sur des soucis simple mais pas parfait\n",
    "* En utilisant le model il semble y avoir conservation du context\n",
    "    * Pour vérifier réinitialisé l'appel entre chaque"
   ],
   "id": "777256518e6c8f42"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Initialisation du model",
   "id": "f6a5e148407fe210"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-02T10:34:24.017320Z",
     "start_time": "2025-08-02T10:34:22.694241Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM"
   ],
   "id": "2612531cdf85d1be",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-02T10:34:34.577125Z",
     "start_time": "2025-08-02T10:34:34.378519Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Création du tokenniser\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Chargement du model\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "# On declare en global (beurk !) le device pour tester\n",
    "device = None\n",
    "\n",
    "# Vérifie si le GPU est disponible avant de continuer, on met alors à jour device\n",
    "if torch.cuda.is_available():\n",
    "    # Sélectionne spécifiquement le premier GPU (device 0)\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    print(\"Utilisation du GPU :\", torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"GPU non trouvé, utilisation du CPU.\")\n",
    "\n",
    "# Déplace le modèle vers le GPU 0\n",
    "# ca plante !\n",
    "model.to(device)\n"
   ],
   "id": "cb713a8b98b6a819",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Utilisation du GPU : NVIDIA GeForce RTX 3080 Ti\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CodeGenForCausalLM(\n",
       "  (transformer): CodeGenModel(\n",
       "    (wte): Embedding(51200, 1024)\n",
       "    (drop): Dropout(p=0.0, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-19): 20 x CodeGenBlock(\n",
       "        (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): CodeGenAttention(\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (qkv_proj): Linear(in_features=1024, out_features=3072, bias=False)\n",
       "          (out_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        )\n",
       "        (mlp): CodeGenMLP(\n",
       "          (fc_in): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc_out): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=1024, out_features=51200, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-02T10:34:38.779413Z",
     "start_time": "2025-08-02T10:34:38.777647Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Parametres du model\n",
    "\n",
    "max_length=200,  # Adjust as needed\n",
    "num_beams=5,      # Adjust for quality/speed trade-off\n",
    "temperature=0.7,  # Adjust for creativity (higher = more creative)\n",
    "top_k=40,         # Adjust for sampling\n",
    "top_p=0.95,        # Adjust for sampling\n",
    "pad_token_id=tokenizer.eos_token_id # Important for some models"
   ],
   "id": "f5e531cd898ec3a4",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-02T10:34:42.479219Z",
     "start_time": "2025-08-02T10:34:42.476543Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def do_predict(model,\n",
    "               prompt: str,\n",
    "               max_length: int = 200,\n",
    "               temperature: float = 0.7,\n",
    "               top_k: int = 40,\n",
    "               top_p: float = 0.9,\n",
    "               pad_token_id: int = tokenizer.eos_token_id):\n",
    "    print(f\"Prompte : {prompt}\\n----\")\n",
    "    input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids\n",
    "\n",
    "    # On doit transférer les sequence de token dans le GPU.\n",
    "    input_ids = input_ids.to(device)\n",
    "\n",
    "    print(f\"Input ids : {input_ids}\")\n",
    "    print(\"---\")\n",
    "    generated_ids = model.generate(input_ids,\n",
    "                                   max_length=max_length,\n",
    "                                   temperature=temperature,\n",
    "                                   top_k=top_k,\n",
    "                                   top_p=top_p,\n",
    "                                   pad_token_id=pad_token_id,\n",
    "                                   do_sample=True)\n",
    "    print(\"----\")\n",
    "    print(generated_ids[0])\n",
    "    print(\"----\")\n",
    "    return tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n"
   ],
   "id": "d47a6779768f2283",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Utilisation pour faire de la completion de code\n",
    "\n",
    "On fournis un fragment de code et on demande au modele de compléter."
   ],
   "id": "40a2c835d1b61720"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-02T10:34:52.901775Z",
     "start_time": "2025-08-02T10:34:52.900494Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "59a259e1b78b05ee",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-08-02T10:34:55.861547Z",
     "start_time": "2025-08-02T10:34:54.627845Z"
    }
   },
   "source": [
    "text = \"\"\"\n",
    "a = 1\n",
    "b = 2\n",
    "if a > b:\n",
    "    print(f\"{a} est supérieur à {b}\"\n",
    "else:\n",
    "\"\"\"\n",
    "\n",
    "print(do_predict(model, text))\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompte : \n",
      "a = 1\n",
      "b = 2\n",
      "if a > b:\n",
      "    print(f\"{a} est supérieur à {b}\"\n",
      "else:\n",
      "\n",
      "----\n",
      "Input ids : tensor([[  198,    64,   796,   352,   198,    65,   796,   362,   198,   361,\n",
      "           257,  1875,   275,    25,   198, 50284,  4798,     7,    69,     1,\n",
      "            90,    64,    92,  1556,  7418,  2634,  5034,   333, 28141,  1391,\n",
      "            65, 36786,   198, 17772,    25,   198]], device='cuda:0')\n",
      "---\n",
      "----\n",
      "tensor([  198,    64,   796,   352,   198,    65,   796,   362,   198,   361,\n",
      "          257,  1875,   275,    25,   198, 50284,  4798,     7,    69,     1,\n",
      "           90,    64,    92,  1556,  7418,  2634,  5034,   333, 28141,  1391,\n",
      "           65, 36786,   198, 17772,    25,   198, 50284,  4798,     7,    69,\n",
      "            1,    90,    64,    92,  1556, 38251, 13528, 28141,  1391,    65,\n",
      "        36786,   198,     8,   198,   198,   361,   257,  6624,   275,    25,\n",
      "          198, 50284,  4798,     7,    69,     1,    90,    64,    92,  1556,\n",
      "        38251, 13528, 28141,  1391,    65, 36786,   198,     8,   198,   198,\n",
      "          361,   257,  6624,   275,    25,   198, 50284,  4798,     7,    69,\n",
      "            1,    90,    64,    92,  1556, 38251, 13528, 28141,  1391,    65,\n",
      "        36786,   198,     8,   198,   198,   361,   257,  6624,   275,    25,\n",
      "          198, 50284,  4798,     7,    69,     1,    90,    64,    92,  1556,\n",
      "        38251, 13528, 28141,  1391,    65, 36786,   198,     8,   198,   198,\n",
      "          361,   257,  6624,   275,    25,   198, 50284,  4798,     7,    69,\n",
      "            1,    90,    64,    92,  1556, 38251, 13528, 28141,  1391,    65,\n",
      "        36786,   198,     8,   198,   198,   361,   257,  6624,   275,    25,\n",
      "          198, 50284,  4798,     7,    69,     1,    90,    64,    92,  1556,\n",
      "        38251, 13528, 28141,  1391,    65, 36786,   198,     8,   198,   198,\n",
      "          361,   257,  6624,   275,    25,   198, 50284,  4798,     7,    69,\n",
      "            1,    90,    64,    92,  1556, 38251, 13528, 28141,  1391,    65],\n",
      "       device='cuda:0')\n",
      "----\n",
      "\n",
      "a = 1\n",
      "b = 2\n",
      "if a > b:\n",
      "    print(f\"{a} est supérieur à {b}\"\n",
      "else:\n",
      "    print(f\"{a} est égal à {b}\"\n",
      ")\n",
      "\n",
      "if a == b:\n",
      "    print(f\"{a} est égal à {b}\"\n",
      ")\n",
      "\n",
      "if a == b:\n",
      "    print(f\"{a} est égal à {b}\"\n",
      ")\n",
      "\n",
      "if a == b:\n",
      "    print(f\"{a} est égal à {b}\"\n",
      ")\n",
      "\n",
      "if a == b:\n",
      "    print(f\"{a} est égal à {b}\"\n",
      ")\n",
      "\n",
      "if a == b:\n",
      "    print(f\"{a} est égal à {b}\"\n",
      ")\n",
      "\n",
      "if a == b:\n",
      "    print(f\"{a} est égal à {b\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-02T10:36:02.885367Z",
     "start_time": "2025-08-02T10:36:01.885445Z"
    }
   },
   "cell_type": "code",
   "source": "print(do_predict(model, text, temperature=1))",
   "id": "adc34b199a9402e5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompte : \n",
      "a = 1\n",
      "b = 2\n",
      "if a > b:\n",
      "    print(f\"{a} est supérieur à {b}\"\n",
      "else:\n",
      "\n",
      "----\n",
      "Input ids : tensor([[  198,    64,   796,   352,   198,    65,   796,   362,   198,   361,\n",
      "           257,  1875,   275,    25,   198, 50284,  4798,     7,    69,     1,\n",
      "            90,    64,    92,  1556,  7418,  2634,  5034,   333, 28141,  1391,\n",
      "            65, 36786,   198, 17772,    25,   198]], device='cuda:0')\n",
      "---\n",
      "----\n",
      "tensor([  198,    64,   796,   352,   198,    65,   796,   362,   198,   361,\n",
      "          257,  1875,   275,    25,   198, 50284,  4798,     7,    69,     1,\n",
      "           90,    64,    92,  1556,  7418,  2634,  5034,   333, 28141,  1391,\n",
      "           65, 36786,   198, 17772,    25,   198, 50284,  4798,     7,    69,\n",
      "            1,    90,    64,    92,  1556, 38251, 13528, 28141,  1391,    65,\n",
      "        36786,   198,     8,   198,   198,   361,   257,  6624,   275,    25,\n",
      "          198, 50284,  4798,     7,    69,     1,    90,    64,    92,  1556,\n",
      "        38251, 13528, 28141,  1391,    65, 36786,   198,     8,   198, 17772,\n",
      "           25,   198, 50284,  4798,     7,    69,     1,    90,    64,    92,\n",
      "         1556, 38251, 13528, 28141,  1391,    65, 36786,   198,     8,   198,\n",
      "          198,   361,   257,  6624,   275,    25,   198, 50284,  4798,     7,\n",
      "           69,     1,    90,    64,    92,  1556, 38251, 13528, 28141,  1391,\n",
      "           65, 36786,   198,     8,   198, 17772,    25,   198, 50284,  4798,\n",
      "            7,    69,     1,    90,    64,    92,  1556, 38251, 13528, 28141,\n",
      "         1391,    65, 36786,   198,     8,   198,   198,   361,   257,  6624,\n",
      "          275,    25,   198, 50284,  4798,     7,    69,     1,    90,    64,\n",
      "           92,  1556, 38251, 13528, 28141,  1391,    65, 36786,   198,     8,\n",
      "          198, 17772,    25,   198, 50284,  4798,     7,    69,     1,    90,\n",
      "           64,    92,  1556, 38251, 13528, 28141,  1391,    65, 36786,   198,\n",
      "            8,   198,   198,   361,   257,  6624,   275,    25,   198, 50284],\n",
      "       device='cuda:0')\n",
      "----\n",
      "\n",
      "a = 1\n",
      "b = 2\n",
      "if a > b:\n",
      "    print(f\"{a} est supérieur à {b}\"\n",
      "else:\n",
      "    print(f\"{a} est égal à {b}\"\n",
      ")\n",
      "\n",
      "if a == b:\n",
      "    print(f\"{a} est égal à {b}\"\n",
      ")\n",
      "else:\n",
      "    print(f\"{a} est égal à {b}\"\n",
      ")\n",
      "\n",
      "if a == b:\n",
      "    print(f\"{a} est égal à {b}\"\n",
      ")\n",
      "else:\n",
      "    print(f\"{a} est égal à {b}\"\n",
      ")\n",
      "\n",
      "if a == b:\n",
      "    print(f\"{a} est égal à {b}\"\n",
      ")\n",
      "else:\n",
      "    print(f\"{a} est égal à {b}\"\n",
      ")\n",
      "\n",
      "if a == b:\n",
      "    \n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-02T10:36:06.112919Z",
     "start_time": "2025-08-02T10:36:05.025912Z"
    }
   },
   "cell_type": "code",
   "source": "print(do_predict(model, text, temperature=0.01))",
   "id": "dcc75ca4f08abd67",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompte : \n",
      "a = 1\n",
      "b = 2\n",
      "if a > b:\n",
      "    print(f\"{a} est supérieur à {b}\"\n",
      "else:\n",
      "\n",
      "----\n",
      "Input ids : tensor([[  198,    64,   796,   352,   198,    65,   796,   362,   198,   361,\n",
      "           257,  1875,   275,    25,   198, 50284,  4798,     7,    69,     1,\n",
      "            90,    64,    92,  1556,  7418,  2634,  5034,   333, 28141,  1391,\n",
      "            65, 36786,   198, 17772,    25,   198]], device='cuda:0')\n",
      "---\n",
      "----\n",
      "tensor([  198,    64,   796,   352,   198,    65,   796,   362,   198,   361,\n",
      "          257,  1875,   275,    25,   198, 50284,  4798,     7,    69,     1,\n",
      "           90,    64,    92,  1556,  7418,  2634,  5034,   333, 28141,  1391,\n",
      "           65, 36786,   198, 17772,    25,   198, 50284,  4798,     7,    69,\n",
      "            1,    90,    64,    92,  1556, 38251, 13528, 28141,  1391,    65,\n",
      "        36786,   198,     8,   198,   198,   361,   257,  6624,   275,    25,\n",
      "          198, 50284,  4798,     7,    69,     1,    90,    64,    92,  1556,\n",
      "        38251, 13528, 28141,  1391,    65, 36786,   198,     8,   198,   198,\n",
      "          361,   257,  6624,   275,    25,   198, 50284,  4798,     7,    69,\n",
      "            1,    90,    64,    92,  1556, 38251, 13528, 28141,  1391,    65,\n",
      "        36786,   198,     8,   198,   198,   361,   257,  6624,   275,    25,\n",
      "          198, 50284,  4798,     7,    69,     1,    90,    64,    92,  1556,\n",
      "        38251, 13528, 28141,  1391,    65, 36786,   198,     8,   198,   198,\n",
      "          361,   257,  6624,   275,    25,   198, 50284,  4798,     7,    69,\n",
      "            1,    90,    64,    92,  1556, 38251, 13528, 28141,  1391,    65,\n",
      "        36786,   198,     8,   198,   198,   361,   257,  6624,   275,    25,\n",
      "          198, 50284,  4798,     7,    69,     1,    90,    64,    92,  1556,\n",
      "        38251, 13528, 28141,  1391,    65, 36786,   198,     8,   198,   198,\n",
      "          361,   257,  6624,   275,    25,   198, 50284,  4798,     7,    69,\n",
      "            1,    90,    64,    92,  1556, 38251, 13528, 28141,  1391,    65],\n",
      "       device='cuda:0')\n",
      "----\n",
      "\n",
      "a = 1\n",
      "b = 2\n",
      "if a > b:\n",
      "    print(f\"{a} est supérieur à {b}\"\n",
      "else:\n",
      "    print(f\"{a} est égal à {b}\"\n",
      ")\n",
      "\n",
      "if a == b:\n",
      "    print(f\"{a} est égal à {b}\"\n",
      ")\n",
      "\n",
      "if a == b:\n",
      "    print(f\"{a} est égal à {b}\"\n",
      ")\n",
      "\n",
      "if a == b:\n",
      "    print(f\"{a} est égal à {b}\"\n",
      ")\n",
      "\n",
      "if a == b:\n",
      "    print(f\"{a} est égal à {b}\"\n",
      ")\n",
      "\n",
      "if a == b:\n",
      "    print(f\"{a} est égal à {b}\"\n",
      ")\n",
      "\n",
      "if a == b:\n",
      "    print(f\"{a} est égal à {b\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-02T10:36:14.513939Z",
     "start_time": "2025-08-02T10:36:08.550828Z"
    }
   },
   "cell_type": "code",
   "source": "print(do_predict(model, text, temperature=0.01, max_length=1024))",
   "id": "59174e8596193e39",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompte : \n",
      "a = 1\n",
      "b = 2\n",
      "if a > b:\n",
      "    print(f\"{a} est supérieur à {b}\"\n",
      "else:\n",
      "\n",
      "----\n",
      "Input ids : tensor([[  198,    64,   796,   352,   198,    65,   796,   362,   198,   361,\n",
      "           257,  1875,   275,    25,   198, 50284,  4798,     7,    69,     1,\n",
      "            90,    64,    92,  1556,  7418,  2634,  5034,   333, 28141,  1391,\n",
      "            65, 36786,   198, 17772,    25,   198]], device='cuda:0')\n",
      "---\n",
      "----\n",
      "tensor([  198,    64,   796,  ..., 13528, 28141,  1391], device='cuda:0')\n",
      "----\n",
      "\n",
      "a = 1\n",
      "b = 2\n",
      "if a > b:\n",
      "    print(f\"{a} est supérieur à {b}\"\n",
      "else:\n",
      "    print(f\"{a} est égal à {b}\"\n",
      ")\n",
      "\n",
      "if a == b:\n",
      "    print(f\"{a} est égal à {b}\"\n",
      ")\n",
      "\n",
      "if a == b:\n",
      "    print(f\"{a} est égal à {b}\"\n",
      ")\n",
      "\n",
      "if a == b:\n",
      "    print(f\"{a} est égal à {b}\"\n",
      ")\n",
      "\n",
      "if a == b:\n",
      "    print(f\"{a} est égal à {b}\"\n",
      ")\n",
      "\n",
      "if a == b:\n",
      "    print(f\"{a} est égal à {b}\"\n",
      ")\n",
      "\n",
      "if a == b:\n",
      "    print(f\"{a} est égal à {b}\"\n",
      ")\n",
      "\n",
      "if a == b:\n",
      "    print(f\"{a} est égal à {b}\"\n",
      ")\n",
      "\n",
      "if a == b:\n",
      "    print(f\"{a} est égal à {b}\"\n",
      ")\n",
      "\n",
      "if a == b:\n",
      "    print(f\"{a} est égal à {b}\"\n",
      ")\n",
      "\n",
      "if a == b:\n",
      "    print(f\"{a} est égal à {b}\"\n",
      ")\n",
      "\n",
      "if a == b:\n",
      "    print(f\"{a} est égal à {b}\"\n",
      ")\n",
      "\n",
      "if a == b:\n",
      "    print(f\"{a} est égal à {b}\"\n",
      ")\n",
      "\n",
      "if a == b:\n",
      "    print(f\"{a} est égal à {b}\"\n",
      ")\n",
      "\n",
      "if a == b:\n",
      "    print(f\"{a} est égal à {b}\"\n",
      ")\n",
      "\n",
      "if a == b:\n",
      "    print(f\"{a} est égal à {b}\"\n",
      ")\n",
      "\n",
      "if a == b:\n",
      "    print(f\"{a} est égal à {b}\"\n",
      ")\n",
      "\n",
      "if a == b:\n",
      "    print(f\"{a} est égal à {b}\"\n",
      ")\n",
      "\n",
      "if a == b:\n",
      "    print(f\"{a} est égal à {b}\"\n",
      ")\n",
      "\n",
      "if a == b:\n",
      "    print(f\"{a} est égal à {b}\"\n",
      ")\n",
      "\n",
      "if a == b:\n",
      "    print(f\"{a} est égal à {b}\"\n",
      ")\n",
      "\n",
      "if a == b:\n",
      "    print(f\"{a} est égal à {b}\"\n",
      ")\n",
      "\n",
      "if a == b:\n",
      "    print(f\"{a} est égal à {b}\"\n",
      ")\n",
      "\n",
      "if a == b:\n",
      "    print(f\"{a} est égal à {b}\"\n",
      ")\n",
      "\n",
      "if a == b:\n",
      "    print(f\"{a} est égal à {b}\"\n",
      ")\n",
      "\n",
      "if a == b:\n",
      "    print(f\"{a} est égal à {b}\"\n",
      ")\n",
      "\n",
      "if a == b:\n",
      "    print(f\"{a} est égal à {b}\"\n",
      ")\n",
      "\n",
      "if a == b:\n",
      "    print(f\"{a} est égal à {b}\"\n",
      ")\n",
      "\n",
      "if a == b:\n",
      "    print(f\"{a} est égal à {b}\"\n",
      ")\n",
      "\n",
      "if a == b:\n",
      "    print(f\"{a} est égal à {b}\"\n",
      ")\n",
      "\n",
      "if a == b:\n",
      "    print(f\"{a} est égal à {b}\"\n",
      ")\n",
      "\n",
      "if a == b:\n",
      "    print(f\"{a} est égal à {b}\"\n",
      ")\n",
      "\n",
      "if a == b:\n",
      "    print(f\"{a} est égal à {b}\"\n",
      ")\n",
      "\n",
      "if a == b:\n",
      "    print(f\"{a} est égal à {b}\"\n",
      ")\n",
      "\n",
      "if a == b:\n",
      "    print(f\"{a} est égal à {b}\"\n",
      ")\n",
      "\n",
      "if a == b:\n",
      "    print(f\"{a} est égal à {b}\"\n",
      ")\n",
      "\n",
      "if a == b:\n",
      "    print(f\"{a} est égal à {b}\"\n",
      ")\n",
      "\n",
      "if a == b:\n",
      "    print(f\"{a} est égal à {b}\"\n",
      ")\n",
      "\n",
      "if a == b:\n",
      "    print(f\"{a} est égal à {b}\"\n",
      ")\n",
      "\n",
      "if a == b:\n",
      "    print(f\"{a} est égal à {\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-02T10:40:00.513639Z",
     "start_time": "2025-08-02T10:39:59.400281Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(do_predict(model, \"\"\"\n",
    "genere une fonction pour calculer la somme des 5 premiers chiffres\n",
    "\"\"\"))"
   ],
   "id": "ed3bcf99fe528cdd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompte : \n",
      "genere une fonction pour calculer la somme des 5 premiers chiffres\n",
      "\n",
      "----\n",
      "Input ids : tensor([[  198,  5235,   567, 17809,   277,   261,   596, 12797,  5204,   263,\n",
      "          8591,  3870,  1326,   748,   642,  4199,  3183,   442,   733,   411,\n",
      "           198]], device='cuda:0')\n",
      "---\n",
      "----\n",
      "tensor([  198,  5235,   567, 17809,   277,   261,   596, 12797,  5204,   263,\n",
      "         8591,  3870,  1326,   748,   642,  4199,  3183,   442,   733,   411,\n",
      "          198,  4299,  3870,  1326,    62,   354,   733,   411,     7,    77,\n",
      "         2381,   411,  2599,   198, 50284,  7783,  2160,     7,   600,     7,\n",
      "          354,   733,   260,     8,   329,   442,   733,   260,   287,   965,\n",
      "            7,    77,  2381,   411,  4008,   198,   198,  4798,     7,    82,\n",
      "          296,  1326,    62,   354,   733,   411,     7,    77,  2381,   411,\n",
      "         4008,   198,   198,  4299,  3870,  1326,    62,   354,   733,   411,\n",
      "            7,    77,  2381,   411,  2599,   198, 50284,  7783,  2160,     7,\n",
      "          600,     7,   354,   733,   260,     8,   329,   442,   733,   260,\n",
      "          287,   965,     7,    77,  2381,   411,  4008,   198,   198,  4798,\n",
      "            7,    82,   296,  1326,    62,   354,   733,   411,     7,    77,\n",
      "         2381,   411,  4008,   198,   198,  4299,  3870,  1326,    62,   354,\n",
      "          733,   411,     7,    77,  2381,   411,  2599,   198, 50284,  7783,\n",
      "         2160,     7,   600,     7,   354,   733,   260,     8,   329,   442,\n",
      "          733,   260,   287,   965,     7,    77,  2381,   411,  4008,   198,\n",
      "          198,  4798,     7,    82,   296,  1326,    62,   354,   733,   411,\n",
      "            7,    77,  2381,   411,  4008,   198,   198,  4299,  3870,  1326,\n",
      "           62,   354,   733,   411,     7,    77,  2381,   411,  2599,   198,\n",
      "        50284,  7783,  2160,     7,   600,     7,   354,   733,   260,     8],\n",
      "       device='cuda:0')\n",
      "----\n",
      "\n",
      "genere une fonction pour calculer la somme des 5 premiers chiffres\n",
      "def somme_chiffres(nombres):\n",
      "    return sum(int(chiffre) for chiffre in str(nombres))\n",
      "\n",
      "print(somme_chiffres(nombres))\n",
      "\n",
      "def somme_chiffres(nombres):\n",
      "    return sum(int(chiffre) for chiffre in str(nombres))\n",
      "\n",
      "print(somme_chiffres(nombres))\n",
      "\n",
      "def somme_chiffres(nombres):\n",
      "    return sum(int(chiffre) for chiffre in str(nombres))\n",
      "\n",
      "print(somme_chiffres(nombres))\n",
      "\n",
      "def somme_chiffres(nombres):\n",
      "    return sum(int(chiffre)\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## test du code",
   "id": "f579c5e8dbabfa33"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 1er run\n",
    "\n",
    "Résultant sacrément mauvais par rapport au model de base non finetunné."
   ],
   "id": "b20c794dad5304cb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-02T10:41:10.078059Z",
     "start_time": "2025-08-02T10:41:10.075748Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# (ajout du # car manquant dans la génération) genere une fonction pour calculer la somme des 5 premiers chiffres\n",
    "def somme_chiffres(nombres):\n",
    "    return sum(int(chiffre) for chiffre in str(nombres))\n",
    "return somme_chiffres(nombres)\n",
    "return somme_chiffres(nombres)\n",
    "return somme_chiffres(nombres)\n",
    "return somme_chiffres(nombres)\n",
    "return somme_chiffres(nombres)\n",
    "return somme_chiffres(nombres)\n",
    "return somme_chiffres(nombres)\n",
    "return somme_chiffres(nombres)\n",
    "return somme_chiffres(nombres)\n",
    "return somme_chiffres(nombres)\n",
    "return somme_chiffres(nombres)"
   ],
   "id": "78551c9b97935e99",
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "'return' outside function (1825139391.py, line 4)",
     "output_type": "error",
     "traceback": [
      "  \u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[15]\u001B[39m\u001B[32m, line 4\u001B[39m\n\u001B[31m    \u001B[39m\u001B[31mreturn somme_chiffres(nombres)\u001B[39m\n    ^\n\u001B[31mSyntaxError\u001B[39m\u001B[31m:\u001B[39m 'return' outside function\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 2eme run\n",
    "\n",
    "Pas mieux"
   ],
   "id": "9a77c5b6f579c14e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-02T10:41:26.610638Z",
     "start_time": "2025-08-02T10:41:26.551313Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# (ajout du # car manquant dans la génération) genere une fonction pour calculer la somme des 5 premiers chiffres\n",
    "def somme_chiffres(nombres):\n",
    "    return sum(nombres)\n",
    "\n",
    "print(somme_chiffres(nombres))\n",
    "\n",
    "def somme_chiffres(nombres):\n",
    "    return sum(nombres)\n",
    "\n",
    "print(somme_chiffres(nombres))\n",
    "\n",
    "def somme_chiffres(nombres):\n",
    "    return sum(nombres)\n",
    "\n",
    "print(somme_chiffres(nombres))\n",
    "\n",
    "def somme_chiffres(nombres):\n",
    "    return sum(nombres)\n",
    "\n",
    "print(somme_chiffres(nombres))\n",
    "\n",
    "def somme_chiffres(nombres):\n",
    "    return sum(nombres)"
   ],
   "id": "7832785d34199054",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nombres' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mNameError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[16]\u001B[39m\u001B[32m, line 5\u001B[39m\n\u001B[32m      2\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34msomme_chiffres\u001B[39m(nombres):\n\u001B[32m      3\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28msum\u001B[39m(nombres)\n\u001B[32m----> \u001B[39m\u001B[32m5\u001B[39m \u001B[38;5;28mprint\u001B[39m(somme_chiffres(\u001B[43mnombres\u001B[49m))\n\u001B[32m      7\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34msomme_chiffres\u001B[39m(nombres):\n\u001B[32m      8\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28msum\u001B[39m(nombres)\n",
      "\u001B[31mNameError\u001B[39m: name 'nombres' is not defined"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "3eme run",
   "id": "40118eea696d57d4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-02T10:41:29.321065Z",
     "start_time": "2025-08-02T10:41:29.318792Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# (ajout du # car manquant dans la génération) genere une fonction pour calculer la somme des 5 premiers chiffres\n",
    "def somme_chiffres(nombres):\n",
    "    return sum(int(chiffre) for chiffre in str(nombres))\n",
    "\n",
    "print(somme_chiffres(nombres))\n",
    "\n",
    "def somme_chiffres(nombres):\n",
    "    return sum(int(chiffre) for chiffre in str(nombres))\n",
    "\n",
    "print(somme_chiffres(nombres))\n",
    "\n",
    "def somme_chiffres(nombres):\n",
    "    return sum(int(chiffre) for chiffre in str(nombres))\n",
    "\n",
    "print(somme_chiffres(nombres))\n",
    "\n",
    "def somme_chiffres(nombres):\n",
    "    return sum(int(chiffre)"
   ],
   "id": "521e2ec8e82b0e9a",
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "incomplete input (1080615747.py, line 18)",
     "output_type": "error",
     "traceback": [
      "  \u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[17]\u001B[39m\u001B[32m, line 18\u001B[39m\n\u001B[31m    \u001B[39m\u001B[31mreturn sum(int(chiffre)\u001B[39m\n                           ^\n\u001B[31mSyntaxError\u001B[39m\u001B[31m:\u001B[39m incomplete input\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Bilan\n",
    "\n",
    "Le model fine tunné est bien pire que le model de base, on voit que le format des données en input est trés important.\n",
    "\n",
    "le dataset structuré \"prompt\\ncode\" semble contre productif car le code généré oublis les # pour marqué un commentaires, le code tourne en boucle.\n",
    "\n",
    "Il est super important de préparer le dataset et il semble aussi important de l'interroger dans un format bien définie.\n",
    "\n",
    "## Poursuite des investigations\n",
    "\n",
    "Voir :\n",
    "* [ ] comment faire un bon dataset\n",
    "* [ ] interoger correctement le model\n",
    "*"
   ],
   "id": "8436111be6c994a1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "61025bc135087fb7"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
